{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe from RDD - SparkSQL is for strutured data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[0] at parallelize at <console>:25\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val a = sc.parallelize(1 to 10) // create a simple RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res0: Array[Int] = Array(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b: org.apache.spark.rdd.RDD[(Int, Int)] = MapPartitionsRDD[1] at map at <console>:26\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val b = a.map(x => (x,x+1)) // add the first placeholder + 1 to the second place to get a pair of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res1: Array[(Int, Int)] = Array((1,2), (2,3), (3,4), (4,5), (5,6), (6,7), (7,8), (8,9), (9,10), (10,11))\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataFrame: org.apache.spark.sql.DataFrame = [first: int, second: int]\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dataFrame = b.toDF(\"first\",\"second\")  // create a DataFrame w/ 2 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|first|second|\n",
      "+-----+------+\n",
      "|    1|     2|\n",
      "|    2|     3|\n",
      "|    3|     4|\n",
      "|    4|     5|\n",
      "|    5|     6|\n",
      "|    6|     7|\n",
      "|    7|     8|\n",
      "|    8|     9|\n",
      "|    9|    10|\n",
      "|   10|    11|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataFrame.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame from a List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cartoonCharacters: List[(String, Int)] = List((Bugs,1), (Elmer,5), (Daffy,3), (Sylvester,6), (Tweety,7), (Sam,9), (Porky,8), (Fog Horn,10), (Coyote,2), (Road Runner,4))\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val cartoonCharacters = List((\"Bugs\", 1),(\"Elmer\", 5),(\"Daffy\", 3),(\"Sylvester\", 6),(\"Tweety\",7),\n",
    "                             (\"Sam\",9),(\"Porky\",8),(\"Fog Horn\",10),(\"Coyote\",2),(\"Road Runner\",4))\n",
    "// this is the same for a Sequence as well\n",
    "//  val cartoonCharacters = Seq((\"Bugs\", 1),(\"Elmer\", 5),(\"Daffy\", 3),(\"Sylvester\", 6),(\"Tweety\",7),\n",
    "//                             (\"Sam\",9),(\"Porky\",8),(\"Fog Horn\",10),(\"Coyote\",2),(\"Road Runner\",4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "characterPopularity: org.apache.spark.sql.DataFrame = [Name: string, Popularity: int]\n"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val characterPopularity = cartoonCharacters.toDF(\"Name\", \"Popularity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+\n",
      "|       Name|Popularity|\n",
      "+-----------+----------+\n",
      "|       Bugs|         1|\n",
      "|      Elmer|         5|\n",
      "|      Daffy|         3|\n",
      "|  Sylvester|         6|\n",
      "|     Tweety|         7|\n",
      "|        Sam|         9|\n",
      "|      Porky|         8|\n",
      "|   Fog Horn|        10|\n",
      "|     Coyote|         2|\n",
      "|Road Runner|         4|\n",
      "+-----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "characterPopularity.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "// run some queries\n",
    "characterPopularity.registerTempTable(\"cartoonCharacters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+\n",
      "|Name|Popularity|\n",
      "+----+----------+\n",
      "|Bugs|         1|\n",
      "+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM cartoonCharacters WHERE Name = 'Bugs'\").show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|      10|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select count(*) from cartoonCharacters\").show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferring Schema using StructType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.{SQLContext, Row}\n",
       "import org.apache.spark.sql.types.{IntegerType, StringType, StructField, StructType}\n"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.{SQLContext,Row}\n",
    "import org.apache.spark.sql.types.{IntegerType, StringType, StructField, StructType}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "schema: org.apache.spark.sql.types.StructType = StructType(StructField(Name,StringType,true), StructField(Popluarity Rank,IntegerType,true))\n"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val schema = StructType(Array(StructField(\"Name\", StringType,true),\n",
    "                    StructField(\"Popluarity Rank\", IntegerType, true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cartoonCharStructured: org.apache.spark.rdd.RDD[(String, Int)] = MapPartitionsRDD[155] at map at <console>:28\n"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val cartoonCharStructured = sc.parallelize(Seq(\"Tom\", \"Jerry\", \"Spike\")).map(x => (x,2+x.length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res69: Array[(String, Int)] = Array((Tom,5), (Jerry,7), (Spike,7))\n"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cartoonCharStructured.collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "charStructuredRows: org.apache.spark.rdd.RDD[org.apache.spark.sql.Row] = MapPartitionsRDD[157] at map at <console>:29\n"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val charStructuredRows = cartoonCharStructured.map(x => Row(x._1, x._2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res70: Array[org.apache.spark.sql.Row] = Array([Tom,5], [Jerry,7], [Spike,7])\n"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charStructuredRows.collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "charDataFrame: org.apache.spark.sql.DataFrame = [Name: string, Popluarity Rank: int]\n"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val charDataFrame = spark.createDataFrame(charStructuredRows, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------+\n",
      "| Name|Popluarity Rank|\n",
      "+-----+---------------+\n",
      "|  Tom|              5|\n",
      "|Jerry|              7|\n",
      "|Spike|              7|\n",
      "+-----+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "charDataFrame.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Inferred schema in class see the spark-shell-sparksql-inferred-schema-in-class.txt file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading different formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "starwarsCharacters: org.apache.spark.sql.DataFrame = [name: string, height: int ... 5 more fields]\n"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val starwarsCharacters = (spark.read.format(\"com.databricks.spark.csv\")\n",
    "                          .option(\"header\",\"true\")\n",
    "                          .option(\"inferSchema\",\"true\")\n",
    "                          .option(\"delimiter\",\",\").load(\"/spark-files/StarWars.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------+------+--------+---------+-------+-----------+\n",
      "|            name|height|weight|eyecolor|haircolor|   jedi|    species|\n",
      "+----------------+------+------+--------+---------+-------+-----------+\n",
      "| nakin Skywalker|   188|    84|    blue|    blond|   jedi|      human|\n",
      "|   Padme Amidala|   165|    45|   brown|    brown|no_jedi|      human|\n",
      "|  Luke Skywalker|   172|    77|    blue|    blond|   jedi|      human|\n",
      "|  Leia Skywalker|   150|    49|   brown|    brown|no_jedi|      human|\n",
      "|    Qui-Gon Jinn|   193|    89|    blue|    brown|   jedi|      human|\n",
      "|  Obi-Wan Kenobi|   182|    77|bluegray|   auburn|   jedi|      human|\n",
      "|        Han Solo|   180|    80|   brown|    brown|no_jedi|      human|\n",
      "| Sheev Palpatine|   173|    75|    blue|      red|no_jedi|      human|\n",
      "|           R2-D2|    96|    32|    null|     null|no_jedi|      droid|\n",
      "|           C-3PO|   167|    75|    null|     null|no_jedi|      droid|\n",
      "|            Yoda|    66|    17|   brown|    brown|   jedi|       yoda|\n",
      "|      Darth Maul|   175|    80|  yellow|     none|no_jedi|dathomirian|\n",
      "|           Dooku|   193|    86|   brown|    brown|   jedi|      human|\n",
      "|       Chewbacca|   228|   112|    blue|    brown|no_jedi|    wookiee|\n",
      "|           Jabba|   390|  null|  yellow|     none|no_jedi|       hutt|\n",
      "|Lando Calrissian|   178|    79|   brown|    blank|no_jedi|      human|\n",
      "|       Boba Fett|   183|    78|   brown|    black|no_jedi|      human|\n",
      "|      Jango Fett|   183|    79|   brown|    black|no_jedi|      human|\n",
      "+----------------+------+------+--------+---------+-------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "starwarsCharacters.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "starwarsCharacters.registerTempTable(\"StarWarsCharacters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+------+--------+---------+-------+-------+\n",
      "|     name|height|weight|eyecolor|haircolor|   jedi|species|\n",
      "+---------+------+------+--------+---------+-------+-------+\n",
      "|Chewbacca|   228|   112|    blue|    brown|no_jedi|wookiee|\n",
      "+---------+------+------+--------+---------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM StarWarsCharacters WHERE species = 'wookiee'\").show"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
