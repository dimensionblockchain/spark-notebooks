{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://10.0.2.15:4042\n",
       "SparkContext available as 'sc' (version = 2.4.4, master = local[*], app id = local-1718243916256)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "book: org.apache.spark.rdd.RDD[String] = /user/book.txt MapPartitionsRDD[1] at textFile at <console>:25\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val book = sc.textFile(\"/user/book.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's do a word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res1: Array[String] = Array(1. Paradigms of Artificial Intelligence Programming: Case Studies in Common Lisp, 2. Code: The Hidden Language of Computer Hardware and Software, 3. An introduction to algorithms, 4. Artificial Intelligence: a modern approach, 5. ON LISP, 6. ANSI COMMON LISP, 7. LISP IN SMALL PIECES, 8. THE LITTLE LISPER, 9. THE SEASONED SCHEMER)\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book.collect // let's read the list of books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res2: Long = 9\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book.count // it found 9 'points' to count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bookSplit: org.apache.spark.rdd.RDD[Array[String]] = MapPartitionsRDD[2] at map at <console>:26\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val bookSplit = book.map( x => x.split(\" \") ) // let's break it down by splitting into arrays by spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res5: Array[Array[String]] = Array(Array(1., Paradigms, of, Artificial, Intelligence, Programming:, Case, Studies, in, Common, Lisp), Array(2., Code:, The, Hidden, Language, of, Computer, Hardware, and, Software), Array(3., An, introduction, to, algorithms), Array(4., Artificial, Intelligence:, a, modern, approach), Array(5., ON, LISP), Array(6., ANSI, COMMON, LISP), Array(7., LISP, IN, SMALL, PIECES), Array(8., THE, LITTLE, LISPER), Array(9., THE, SEASONED, SCHEMER))\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bookSplit.collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bookFlat: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[3] at flatMap at <console>:26\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val bookFlat = book.flatMap( x => x.split(\" \")) // make a single array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res8: Array[String] = Array(1., Paradigms, of, Artificial, Intelligence, Programming:, Case, Studies, in, Common, Lisp, 2., Code:, The, Hidden, Language, of, Computer, Hardware, and, Software, 3., An, introduction, to, algorithms, 4., Artificial, Intelligence:, a, modern, approach, 5., ON, LISP, 6., ANSI, COMMON, LISP, 7., LISP, IN, SMALL, PIECES, 8., THE, LITTLE, LISPER, 9., THE, SEASONED, SCHEMER)\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bookFlat.collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bookWordMap: org.apache.spark.rdd.RDD[(String, Int)] = MapPartitionsRDD[5] at map at <console>:26\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val bookWordMap = bookFlat.map( i => (i,1)) // assign a value of 1 to everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res10: Array[(String, Int)] = Array((1.,1), (Paradigms,1), (of,1), (Artificial,1), (Intelligence,1), (Programming:,1), (Case,1), (Studies,1), (in,1), (Common,1), (Lisp,1), (2.,1), (Code:,1), (The,1), (Hidden,1), (Language,1), (of,1), (Computer,1), (Hardware,1), (and,1), (Software,1), (3.,1), (An,1), (introduction,1), (to,1), (algorithms,1), (4.,1), (Artificial,1), (Intelligence:,1), (a,1), (modern,1), (approach,1), (5.,1), (ON,1), (LISP,1), (6.,1), (ANSI,1), (COMMON,1), (LISP,1), (7.,1), (LISP,1), (IN,1), (SMALL,1), (PIECES,1), (8.,1), (THE,1), (LITTLE,1), (LISPER,1), (9.,1), (THE,1), (SEASONED,1), (SCHEMER,1))\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bookWordMap.collect // see the assigned value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bookReduce: org.apache.spark.rdd.RDD[(String, Int)] = ShuffledRDD[6] at reduceByKey at <console>:26\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val bookReduce = bookWordMap.reduceByKey((x,y) => (x+y)) // merging values for each key by adding them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res11: Array[(String, Int)] = Array((Case,1), (Artificial,2), (2.,1), (Hardware,1), (Hidden,1), (introduction,1), (Paradigms,1), (SEASONED,1), (Lisp,1), (8.,1), (approach,1), (LITTLE,1), (Language,1), (4.,1), (LISP,3), (algorithms,1), (6.,1), (Software,1), (5.,1), (The,1), (Computer,1), (Intelligence,1), (7.,1), (Studies,1), (a,1), (Code:,1), (ANSI,1), (SCHEMER,1), (LISPER,1), (SMALL,1), (COMMON,1), (1.,1), (to,1), (in,1), (Common,1), (THE,2), (of,2), (ON,1), (An,1), (Programming:,1), (3.,1), (PIECES,1), (Intelligence:,1), (and,1), (9.,1), (IN,1), (modern,1))\n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bookReduce.collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bookCountAllInOne: Array[(String, Int)] = Array((Case,1), (Artificial,2), (2.,1), (Hardware,1), (Hidden,1), (introduction,1), (Paradigms,1), (SEASONED,1), (Lisp,1), (8.,1), (approach,1), (LITTLE,1), (Language,1), (4.,1), (LISP,3), (algorithms,1), (6.,1), (Software,1), (5.,1), (The,1), (Computer,1), (Intelligence,1), (7.,1), (Studies,1), (a,1), (Code:,1), (ANSI,1), (SCHEMER,1), (LISPER,1), (SMALL,1), (COMMON,1), (1.,1), (to,1), (in,1), (Common,1), (THE,2), (of,2), (ON,1), (An,1), (Programming:,1), (3.,1), (PIECES,1), (Intelligence:,1), (and,1), (9.,1), (IN,1), (modern,1))\n"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val bookCountAllInOne = book.flatMap( x => x.split(\" \")).map(y => (y,1)).reduceByKey((x,y) => (x+y)).collect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The final count the whole thing wrapped up in one line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
